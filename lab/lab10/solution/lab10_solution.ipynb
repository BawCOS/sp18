{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab 10: Feature Engineering & Cross-Validation\n",
    "** This assignment is due 04/04/2018 at 11:59pm (graded on accuracy) **\n",
    "\n",
    "In this lab, you will practice using scikit-learn to do feature engineering and cross-validation to produce a model with low error on held-out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "from IPython.display import display, Latex, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Introduction\n",
    "\n",
    "For this lab, we will use a toy dataset to predict the house prices in Boston with data provided by the `sklearn.datasets` package.\n",
    "\n",
    "Run the following cell to load the data. This will return a dictionary object which includes keys for:\n",
    "    - `data` : the covariates (X)\n",
    "    - `target` : the response vector (Y)\n",
    "    - `feature_names`: the column names\n",
    "    - `DESCR` : a full description of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "load_data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston_data = load_boston()\n",
    "print(boston_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston_data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "data_description",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "A look at the `DESCR` attribute tells us the data contains these features:\n",
    "\n",
    "    1. CRIM      per capita crime rate by town\n",
    "    2. ZN        proportion of residential land zoned for lots over \n",
    "                 25,000 sq.ft.\n",
    "    3. INDUS     proportion of non-retail business acres per town\n",
    "    4. CHAS      Charles River dummy variable (= 1 if tract bounds \n",
    "                 river; 0 otherwise)\n",
    "    5. NOX       nitric oxides concentration (parts per 10 million)\n",
    "    6. RM        average number of rooms per dwelling\n",
    "    7. AGE       proportion of owner-occupied units built prior to 1940\n",
    "    8. DIS       weighted distances to five Boston employment centres\n",
    "    9. RAD       index of accessibility to radial highways\n",
    "    10. TAX      full-value property-tax rate per 10,000 USD\n",
    "    11. PTRATIO  pupil-teacher ratio by town\n",
    "    12. B        1000(Bk - 0.63)^2 where Bk is the proportion of black \n",
    "                 residents by town\n",
    "    13. LSTAT    % lower status of the population\n",
    "    \n",
    "Let's now convert this data into a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "data_head",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "boston = pd.DataFrame(boston_data['data'], columns=boston_data['feature_names'])\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1\n",
    "\n",
    "Let's model this housing price data! Before we can do this, however, we need to split the data into training and test sets. The latter, held-out points will be used to choose the best performing model. Remember that the response vector (housing prices) lives in the `target` attribute.\n",
    "\n",
    "Use the [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function to split out 10% of the data for test. Call the resulting splits `X_train`, `X_test`, `Y_train`, `Y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(47)\n",
    "\n",
    "X = boston\n",
    "Y = pd.Series(boston_data['target'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = ...,...,...,...\n",
    "### BEGIN SOLUTION\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.10)\n",
    "### END SOLUTION\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q1_test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "test",
     "q01"
    ]
   },
   "outputs": [],
   "source": [
    "assert X_train.shape == (455, 13)\n",
    "assert X_test.shape == (51, 13)\n",
    "assert Y_train.shape == (455, )\n",
    "assert Y_test.shape == (51, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2\n",
    "\n",
    "As a warmup, fit a linear model to describe the relationship between the housing price and all available covariates. We've imported `sklearn.linear_model` as lm, so you can use that instead of typing out the whole module name. Running the cell should create a scatter plot for our predictions vs the true prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "linear_model = lm.LinearRegression()\n",
    "\n",
    "\n",
    "# Fit your classifier\n",
    "#linear_model.fit(...)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "linear_model.fit(X_train, Y_train)\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2b_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Predict housing prices on the test set\n",
    "Y_pred = ... # linear_model.predict(...)\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "Y_pred = linear_model.predict(X_test)\n",
    "### END SOLUTION\n",
    "\n",
    "# Plot predicted vs true prices\n",
    "plt.scatter(Y_test, Y_pred, alpha=0.5)\n",
    "plt.xlabel(\"Prices\")\n",
    "plt.ylabel(\"Predicted prices\")\n",
    "plt.title(\"Prices vs Predicted prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 3\n",
    "\n",
    "As we find from the scatter plot, our model is not perfect. If it were perfect, we would see the identity line (i.e. a line of slope 1). Compute the root mean squared error (RMSE) of the predicted responses: \n",
    "\n",
    "$$\n",
    "\\textbf{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n \\left( y_i - \\hat{y}_i \\right)^2 }\n",
    "$$\n",
    "\n",
    "Fill out the function below and compute the RMSE for our predictions on both the training data `X_train` and the test set `X_test`.  Note your implementation should not contain the word **\"for\"** (...that would be very slow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def rmse(actual_y, predicted_y):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        predicted_y: an array of the prediction from the model\n",
    "        actual_y: an array of the groudtruth label\n",
    "        \n",
    "    Returns:\n",
    "        The root mean square error between the prediction and the groudtruth\n",
    "    \"\"\"\n",
    "### BEGIN SOLUTION\n",
    "    return np.sqrt(np.mean((actual_y - predicted_y) ** 2))\n",
    "### END SOLUTION\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_code2",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "train_error = ...\n",
    "test_error = ...\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "train_error = rmse(Y_train, linear_model.predict(X_train))\n",
    "test_error = rmse(Y_test, Y_pred)\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Training RMSE:\", train_error)\n",
    "print(\"Test RMSE:\", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q3_test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "test",
     "q03"
    ]
   },
   "outputs": [],
   "source": [
    "assert np.allclose((train_error, test_error), (4.56291225689, 5.88492861688))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cv",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Cross Validation\n",
    "\n",
    "**Warning**: don't use the test set to perform the feature selection! It may lead to over-fitting. We want to avoid using the test set too frequently. When selecting features or choosing hyper-parameters, we can split the training set further into train and validation sets. Then we can use the validation error to help select hyper-parameters.\n",
    "\n",
    "Try $k$-fold cross-validation to select the best subset of features for our model. Recall the approach looks something like:\n",
    "\n",
    "<img src=\"cv.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Scikit-learn has built-in support for cross validation.  However, to better understand how cross validation works complete the following function which cross validates a given model.\n",
    "\n",
    "1. Use the [`KFold.split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) function to get 4 splits on the training data. Note that `split` returns the indices of the data for that split.\n",
    "2. For each split, select out the rows and columns based on the split indices and features.\n",
    "3. Compute the RMSE on the validation split.\n",
    "4. Return the average error across all cross validation splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def compute_CV_error(model, X_train, Y_train):\n",
    "    '''\n",
    "    Split the training data into 4 subsets.\n",
    "    For each subset, \n",
    "        fit a model holding out that subset\n",
    "        compute the MSE on that subset (the validation set)\n",
    "    You should be fitting 4 models total.\n",
    "    Return the average MSE of these 4 folds.\n",
    "\n",
    "    Args:\n",
    "        model: an sklearn model with fit and predict functions \n",
    "        X_train (data_frame): Training data\n",
    "        Y_train (data_frame): Label \n",
    "\n",
    "    Return:\n",
    "        the average validation MSE for the 4 splits.\n",
    "    '''\n",
    "    kf = KFold(n_splits=4)\n",
    "    validation_errors = []\n",
    "    \n",
    "    for train_idx, valid_idx in kf.split(X_train):\n",
    "        # split the data\n",
    "        split_X_train, split_X_valid = ..., ...\n",
    "        split_Y_train, split_Y_valid = ..., ...\n",
    "\n",
    "        # Fit the model on the training split\n",
    "        ...\n",
    "        \n",
    "        # Compute the RMSE on the validation split\n",
    "        error = ...\n",
    "\n",
    "        ### BEGIN SOLUTION\n",
    "        # split the data\n",
    "        split_X_train, split_X_valid = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "        split_Y_train, split_Y_valid = Y_train.iloc[train_idx], Y_train.iloc[valid_idx]\n",
    "      \n",
    "        # Fit the model on the training split\n",
    "        model.fit(split_X_train, split_Y_train)\n",
    "        \n",
    "        error = rmse(model.predict(split_X_valid), split_Y_valid)\n",
    "        ### END SOLUTION\n",
    "        \n",
    "        validation_errors.append(error)\n",
    "        \n",
    "    return np.mean(validation_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q5_test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(\n",
    "    compute_CV_error(lm.LinearRegression(), X_train[['TAX', 'INDUS', 'CRIM']],Y_train),\n",
    "    7.5974094557701459)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Use the above cross validation function to determine which of the following feature sets to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q5_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "feature_sets = [\n",
    "    ['TAX', 'INDUS', 'CRIM'], \n",
    "    ['RM', 'LSTAT', 'PTRATIO'], \n",
    "    ['RM', 'B', 'NOX'], \n",
    "    ['TAX', 'LSTAT', 'DIS']\n",
    "]\n",
    "\n",
    "errors = []\n",
    "for feat in feature_sets:\n",
    "    print(\"Trying features:\", feat)\n",
    "    model = lm.LinearRegression()\n",
    "    error = ... # compute the cross validation error\n",
    "    print(\"\\tRMSE:\", error)\n",
    "    errors.append(error)\n",
    "\n",
    "best_err_idx = ...\n",
    "best_err = ...\n",
    "best_feature_set = ...\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "print(\"\\n\\nBegin Solution\")\n",
    "errors = []\n",
    "for feat in feature_sets:\n",
    "    print(\"Trying features:\", feat)\n",
    "    model = lm.LinearRegression()\n",
    "    error = compute_CV_error(model, X_train[feat],Y_train)\n",
    "    print(\"\\tRMSE:\", error)\n",
    "    errors.append(error)    \n",
    "\n",
    "best_err_idx = np.argmin(errors)\n",
    "best_err = errors[best_err_idx]\n",
    "best_feature_set = feature_sets[best_err_idx]\n",
    "### END SOLUTION\n",
    "\n",
    "for i in range(4):\n",
    "    print('{}, error: {}'.format(feature_sets[i], errors[i]))\n",
    "\n",
    "best_feature_set, best_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q5_test2",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "test",
     "q05"
    ]
   },
   "outputs": [],
   "source": [
    "assert best_feature_set == ['RM', 'LSTAT', 'PTRATIO']\n",
    "assert np.isclose(best_err, 5.221575997721903)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 6\n",
    "Finally, fit a linear classifier using your best feature set and predict housing prices for your original test set. Compute the final MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Fit your classifier\n",
    "...\n",
    "\n",
    "# Predict points from our test set and calculate the mse\n",
    "train_rmse = ... \n",
    "test_rmse = ...\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "model = lm.LinearRegression()\n",
    "model.fit(X_train[best_feature_set], Y_train)\n",
    "train_rmse = rmse(model.predict(X_train[best_feature_set]), Y_train) \n",
    "test_rmse = rmse(model.predict(X_test[best_feature_set]), Y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Train RMSE\", train_rmse)\n",
    "print(\"KFold Validation RMSE\", best_err)\n",
    "print(\"Test RMSE\", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "concluding-thought",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Notice that the test error is higher than the validation error which is higher than the training error.  Why is this the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q6_test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "test",
     "q06"
    ]
   },
   "outputs": [],
   "source": [
    "assert np.abs(test_rmse - 5.846401452163672) < 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cv_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Nice! You've used $k$-fold cross-validation to fit a linear regression model to the housing data.\n",
    "\n",
    "In the future, you'd probably want to use something like [`cross_val_predict`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) to automatically perform cross-validation, but it's instructive to do it yourself at least once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Submission\n",
    "\n",
    "Congrats! You are finished with this assignment. Please don't forget to submit by 11:59 pm!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
