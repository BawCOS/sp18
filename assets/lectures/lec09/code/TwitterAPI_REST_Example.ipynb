{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting with REST APIs\n",
    "\n",
    "In this lecture we will use the public Twitter APIs to interact with Twitter.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining my Twitter Keys\n",
    "\n",
    "To interact with Twitter we need to deal with OAuth security authentication.  (This is complicated!!)  Fortunately, Twitter offers a simple way to obtain a secure Token for single user applications.  You will learn how to create a Twitter developer account and access token in Project 1.  \n",
    "\n",
    "https://twitter.com/data_100\n",
    "\n",
    "I have setup a developer account and created an application.  In the process Twitter generates a set of keys for me which I have stored in my key file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:12.272213Z",
     "start_time": "2018-02-13T08:26:12.267919Z"
    }
   },
   "outputs": [],
   "source": [
    "keyfile = '/Users/jegonzal/Documents/keys/data100_twitter_api.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you like to see it's contents?  (Do I want students tweeting as me?)\n",
    "\n",
    "Here is what a fake file looks like (these keys are not real...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:12.283221Z",
     "start_time": "2018-02-13T08:26:12.275601Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(keyfile + \".fake\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally the values are all secret.  Now let's load the real deal.\n",
    "\n",
    "### Json loader\n",
    "\n",
    "The following reads the JSON file into a python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:12.295344Z",
     "start_time": "2018-02-13T08:26:12.288013Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "key_file = '/Users/jegonzal/Documents/keys/data100_twitter_api.json'\n",
    "with open(key_file) as f:\n",
    "    auth_keys = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can examine my keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:12.315538Z",
     "start_time": "2018-02-13T08:26:12.301395Z"
    }
   },
   "outputs": [],
   "source": [
    "auth_keys.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I won't examine the values ... (Why?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Requests Session\n",
    "\n",
    "I will use the request `oauth` support to start an Authenticated session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:12.491259Z",
     "start_time": "2018-02-13T08:26:12.318466Z"
    }
   },
   "outputs": [],
   "source": [
    "from requests_oauthlib import OAuth1Session\n",
    "session = OAuth1Session(auth_keys[\"consumer_key\"],\n",
    "                        client_secret=auth_keys[\"consumer_secret\"],\n",
    "                        resource_owner_key=auth_keys[\"access_token\"],\n",
    "                        resource_owner_secret=auth_keys[\"access_token_secret\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Twitter REST APIs\n",
    "\n",
    "We want to get all the Tweets from a user.  To do this we will use the timeline API:\n",
    "\n",
    "https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline.html\n",
    "\n",
    "Skim the above web page to see how we call this API.  What do we need to know:\n",
    "\n",
    "1. What kind of request (`GET`, `POST`, ...)?\n",
    "1. What are the parameters or data that we should send?\n",
    "1. What are the returned fields?\n",
    "1. Rate limits ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Timeline\n",
    "\n",
    "The following will get the Timeline for `\"UCBIDS\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:15.689011Z",
     "start_time": "2018-02-13T08:26:12.493586Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://api.twitter.com/1.1/statuses/user_timeline.json\"\n",
    "resp = session.get(url, params={\"screen_name\": \"UCBIDS\"})\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Response\n",
    "1. What is it's format?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:15.696961Z",
     "start_time": "2018-02-13T08:26:15.691755Z"
    }
   },
   "outputs": [],
   "source": [
    "dict(resp.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:15.706056Z",
     "start_time": "2018-02-13T08:26:15.699622Z"
    }
   },
   "outputs": [],
   "source": [
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the JSON Content\n",
    "\n",
    "The response is encoded in JSON (see headers or the content).  We will use the json parsing library built into python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:15.752875Z",
     "start_time": "2018-02-13T08:26:15.708193Z"
    }
   },
   "outputs": [],
   "source": [
    "bd_tweets = json.loads(resp.content)\n",
    "bd_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many tweets did we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:15.758771Z",
     "start_time": "2018-02-13T08:26:15.754833Z"
    }
   },
   "outputs": [],
   "source": [
    "len(bd_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining a Tweet\n",
    "\n",
    "1. What fields do we have?\n",
    "1. What is the recursive structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:15.767745Z",
     "start_time": "2018-02-13T08:26:15.761306Z"
    }
   },
   "outputs": [],
   "source": [
    "bd_tweets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining First 5 Tweets:\n",
    "\n",
    "We can loop over the dictionaries and print fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:15.776334Z",
     "start_time": "2018-02-13T08:26:15.770559Z"
    }
   },
   "outputs": [],
   "source": [
    "for t in bd_tweets[:5]:\n",
    "    print(t['created_at'])\n",
    "    print(t['text'], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Dataframe\n",
    "\n",
    "Pandas can build a DataFrame from the dictionaries and even the raw JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:16.126003Z",
     "start_time": "2018-02-13T08:26:15.778916Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(bd_tweets)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:16.184861Z",
     "start_time": "2018-02-13T08:26:16.128116Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(resp.content)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Lots of Tweets\n",
    "\n",
    "The Twitter API limits how many tweets you can obtain in a single request to 200 tweets.  Therefore to go back in time you need to repeatedly call requesting earlier tweets than the oldest tweet you have.  This will return 200 more tweets that are at least as old (including the oldest tweet again ...).\n",
    "\n",
    "This is an excellent example of being stateless.  The Twitter Server does not need to remember which tweets it sent us.  Instead we tell it where to start reading in each request. \n",
    "\n",
    "\n",
    "The following block of code iterates until no new Tweets are returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:16.191756Z",
     "start_time": "2018-02-13T08:26:16.186908Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(bd_tweets[0]['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:16.209633Z",
     "start_time": "2018-02-13T08:26:16.195073Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_timeline(session, screen_name):\n",
    "    \"\"\"\n",
    "    Constructs a dictionary of all available tweets from a given screen name.\n",
    "    session: a request session that has been auntheticated \n",
    "    screen_name: the screen name from which to get the timeline\n",
    "    \n",
    "    returns: a list all tweets\n",
    "    \"\"\"\n",
    "    url = \"https://api.twitter.com/1.1/statuses/user_timeline.json\"\n",
    "    tweets = {}\n",
    "    # Make an initial request\n",
    "    resp = session.get(url, params = {\"screen_name\": screen_name, \"count\": 200})\n",
    "    old_tweetid_len = -1\n",
    "    # Loop while the response is OK and we are still getting new tweets\n",
    "    while resp.ok and old_tweetid_len < len(tweets):\n",
    "        new_tweets = {t['id']: t for t in json.loads(resp.content)}\n",
    "        old_tweetid_len = len(tweets)\n",
    "        tweets.update(new_tweets)\n",
    "        min_id = min(tweets.keys())\n",
    "        resp = session.get(url, params = {\"screen_name\": screen_name, \"count\": 200, \"max_id\": min_id})\n",
    "        print(\"Oldest Tweet:\", tweets[min_id]['created_at'], \"\\\"\", tweets[min_id][\"text\"], \"\\\"\")\n",
    "    return list(tweets.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:17.342578Z",
     "start_time": "2018-02-13T08:26:16.211618Z"
    }
   },
   "outputs": [],
   "source": [
    "all_ds_tweets = get_timeline(session, \"UCBIDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a DataFrame from the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:17.538145Z",
     "start_time": "2018-02-13T08:26:17.345302Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_ds_tweets)[['id', 'created_at', 'text']]\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df['len'] = df['text'].str.len()\n",
    "df = df.sort_values(\"created_at\", ascending=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T01:04:43.027335Z",
     "start_time": "2018-02-12T01:04:43.022164Z"
    }
   },
   "source": [
    "# Post Tweets\n",
    "\n",
    "We can use the Twitter API to also post tweets.  Examine the following page:\n",
    "\n",
    "https://developer.twitter.com/en/docs/tweets/post-and-engage/overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posting \"Hello World\"\n",
    "\n",
    "We will post to the class Twitter Account https://twitter.com/data_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:17.688439Z",
     "start_time": "2018-02-13T08:26:17.540795Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://api.twitter.com/1.1/statuses/update.json\"\n",
    "resp = session.post(url, data = {\"status\": \"Hello World!\"})\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Website\n",
    "\n",
    "https://twitter.com/data_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:17.694738Z",
     "start_time": "2018-02-13T08:26:17.690643Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet = json.loads(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting the Tweet\n",
    "\n",
    "https://developer.twitter.com/en/docs/tweets/post-and-engage/api-reference/post-statuses-destroy-id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:17.801383Z",
     "start_time": "2018-02-13T08:26:17.696862Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://api.twitter.com/1.1/statuses/destroy/{old_id}.json\".format(old_id = tweet['id'])\n",
    "resp = session.post(url)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Website\n",
    "\n",
    "https://twitter.com/data_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liking Everything Culler\n",
    "\n",
    "https://developer.twitter.com/en/docs/tweets/post-and-engage/api-reference/post-favorites-create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:17.816074Z",
     "start_time": "2018-02-13T08:26:17.804160Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['text'].str.contains(\"Culler\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:17.967545Z",
     "start_time": "2018-02-13T08:26:17.818430Z"
    }
   },
   "outputs": [],
   "source": [
    "for tweetid in df[df['text'].str.contains(\"Culler\")]['id']:\n",
    "    url = \"https://api.twitter.com/1.1/favorites/create.json\"\n",
    "    resp = session.post(url, data = {\"id\": tweetid})\n",
    "    print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Website\n",
    "\n",
    "https://twitter.com/data_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disliking Everything Culler\n",
    "\n",
    "https://developer.twitter.com/en/docs/tweets/post-and-engage/api-reference/post-favorites-destroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:26:18.066454Z",
     "start_time": "2018-02-13T08:26:17.969978Z"
    }
   },
   "outputs": [],
   "source": [
    "for tweetid in df[df['text'].str.contains(\"Culler\")]['id']:\n",
    "    url = \"https://api.twitter.com/1.1/favorites/destroy.json\"\n",
    "    resp = session.post(url, data = {\"id\": tweetid})\n",
    "    print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Website\n",
    "\n",
    "https://twitter.com/data_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following a Hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:28:14.288536Z",
     "start_time": "2018-02-13T08:28:14.154321Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://stream.twitter.com/1.1/statuses/filter.json\"\n",
    "resp = session.post(url, data={\"track\": \"datascience\"}, stream=True)\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T08:28:33.520810Z",
     "start_time": "2018-02-13T08:28:16.926604Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    for line in resp.iter_lines():\n",
    "        if len(line) > 0:\n",
    "            try:\n",
    "                tweet = json.loads(line)\n",
    "            except:\n",
    "                print(line)\n",
    "            print(tweet['text'])\n",
    "except:\n",
    "    # It is important to close the connections since there is a limit on the number of active sessions.\n",
    "    print(\"Closing Connection\")\n",
    "    resp.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
